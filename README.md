# Automate_EMR_ETL_pipeline_using_Airflow

This project provides a detailed overview of constructing a fully automated data engineering pipeline. It integrates Apache Airflow for workflow orchestration, utilizes Apache Spark on AWS EMR for large-scale data processing and employs Snowflake for data warehousing. Additionally, Tableau is used for creating visualizations to analyze the real estate market in the USA effectively.

The detailed blog can be found here.

--

To build the entire pipeline, here was the process:
- Configuring the necessary AWS services
- Setting up Airflow
- Data Collection
- Data Transformation using AWS EMR
- Connecting All the Tasks to Create a DAG Pipeline
- Data Warehousing using Snowflake
- Visualization using Tableau


Here's an overview of the complete pipeline:
<img width="1197" alt="Screenshot 2024-08-02 at 2 54 28 PM" src="https://github.com/user-attachments/assets/e2e593db-eebf-4d96-bf8b-15059c7b0c0e">


Here is the final output of the dashboard created using Tableau:

<img width="1167" alt="Screenshot 2024-08-02 at 2 58 27 PM" src="https://github.com/user-attachments/assets/4d618377-35bb-45b5-ad3f-a9b84009d328">



For questions or feedback about the project, don't hesitate to reach out to me on [LinkedIn](https://www.linkedin.com/in/siddhesh-sreedar/).

